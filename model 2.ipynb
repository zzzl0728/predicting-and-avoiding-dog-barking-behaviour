{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = {\n",
    "    0: 'air_conditioner',\n",
    "    1: 'car_horn',\n",
    "    2: 'children_playing',\n",
    "    3: 'dog_bark',\n",
    "    4: 'drilling',\n",
    "    5: 'engine_idling',\n",
    "    6: 'gun_shot',\n",
    "    7: 'jackhammer',\n",
    "    8: 'siren',\n",
    "    9: 'street_music'\n",
    "}\n",
    "\n",
    "# Set the path to the audio files\n",
    "audio_path = r\"C:/Users/zzzl0/Desktop/predicting-and-avoiding-dog-barking-behaviour/predicting-and-avoiding-dog-barking-behaviour/output/model2_audio_clips\"\n",
    "\n",
    "# Initialize the CSV output file\n",
    "output_file = \"classification_results.csv\"\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Dog', 'Audio', 'Sound_Class'])\n",
    "\n",
    "    # Iterate over the audio files\n",
    "    for file in os.listdir(audio_path):\n",
    "        if file.startswith(\"Dog\"):\n",
    "            dog_number = file.split(\"_\")[0][3:]\n",
    "            audio_number = file.split(\"_\")[1]\n",
    "\n",
    "            # Read the audio file\n",
    "            audio_file = os.path.join(audio_path, file)\n",
    "            audio, sr = librosa.load(audio_file)\n",
    "\n",
    "            # Split the audio into clips\n",
    "            clip_length = int(sr)  # Assuming 1-second clips\n",
    "            clips = [audio[i:i+clip_length] for i in range(0, len(audio), clip_length)]\n",
    "\n",
    "            # Classify each clip\n",
    "            for i, clip in enumerate(clips):\n",
    "                # Perform classification using your prebuilt environmental sound classifier\n",
    "                # Replace the following code with your actual classification code\n",
    "                # This code generates random predictions for demonstration purposes\n",
    "                predictions = np.random.rand int(0, len(class_labels), size=len(clip))\n",
    "\n",
    "\n",
    "                # Write the results to the CSV file\n",
    "                writer.writerow([dog_number, audio_number, class_labels[sound_class]])\n",
    "\n",
    "print(\"Classification completed. Results saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio ,sr):\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    mels = librosa.feature.melspectrogram(audio, sr=sr)\n",
    "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
    "\n",
    "    mfccs = mfccs.reshape(1, mfccs.shape[0], mfccs.shape[1], 1)\n",
    "    mels_db = mels_db.reshape(1, mels_db.shape[0], mels_db.shape[1], 1)\n",
    "\n",
    "    prediction = model.predict([mfccs, mels_db])\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "\n",
    "    print(\"Predicted class:\", predicted_class)\n",
    "    return predicted_class\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
