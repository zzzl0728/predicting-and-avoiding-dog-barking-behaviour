{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Enviormental sound classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers import Input, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics \n",
    "# Load metadata\n",
    "metadata = pd.read_csv('C:/Users/zzzl0/Desktop/predicting-and-avoiding-dog-barking-behaviour/predicting-and-avoiding-dog-barking-behaviour/UrbanSound8K/metadata/model1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc\n",
    "max_frames = 174\n",
    "def mfcc_mels(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mels = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "\n",
    "    # Padding\n",
    "    pad_width = max_frames - mfccs.shape[1]\n",
    "    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    pad_width_mels = max_frames - mels.shape[1]\n",
    "    mels = np.pad(mels, pad_width=((0, 0), (0, pad_width_mels)), mode='constant')\n",
    "\n",
    "    return mfccs, mels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "def display_sample_data(features):\n",
    "    random_index = np.random.randint(0, len(features))\n",
    "    random_mfcc = features[random_index][0]\n",
    "    \n",
    "    # Remove the extra dimension if present\n",
    "    if random_mfcc.ndim > 1:\n",
    "        random_mfcc = random_mfcc.squeeze()\n",
    "    \n",
    "    random_mfcc = np.transpose(random_mfcc)  # Transpose the data\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.heatmap(random_mfcc, cmap='viridis')\n",
    "    plt.title('MFCC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature\n",
    "for idx, row in metadata.iterrows():\n",
    "    filename = os.path.join('C:/Users/zzzl0/Desktop/predicting-and-avoiding-dog-barking-behaviour/predicting-and-avoiding-dog-barking-behaviour/UrbanSound8K/audio',\n",
    "                            'fold' + str(row['fold']), row['slice_file_name'])\n",
    "    mfccs, mels = mfcc_mels(filename)\n",
    "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
    "    \n",
    "    # Save MFCC and mel spectrogram as numpy arrays\n",
    "    np.save(f'mfcc/{row[\"slice_file_name\"]}.npy', mfccs)\n",
    "    np.save(f'spectrograms/{row[\"slice_file_name\"]}.npy', mels_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, concatenate, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def multi_input_cnn(input_shape_mfcc, input_shape_mels, num_classes):\n",
    "    # mfcc\n",
    "    input_mfcc = Input(shape=input_shape_mfcc)\n",
    "    x = Conv2D(filters=16, kernel_size=2, activation='relu')(input_mfcc)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=32, kernel_size=2, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=64, kernel_size=2, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(filters=128, kernel_size=2, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # mels\n",
    "    input_mels = Input(shape=input_shape_mels)\n",
    "    y = Conv2D(filters=16, kernel_size=2, activation='relu')(input_mels)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    y = Conv2D(filters=32, kernel_size=2, activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    y = Conv2D(filters=64, kernel_size=2, activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    y = Conv2D(filters=128, kernel_size=2, activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    y = GlobalAveragePooling2D()(y)\n",
    "\n",
    "    combined = concatenate([x, y])\n",
    "\n",
    "    z = Dense(num_classes, activation='softmax')(combined)\n",
    "\n",
    "    model = Model(inputs=[input_mfcc, input_mels], outputs=z)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 174, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 174, 3), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, 128, 174, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model_3\" \"                 f\"(type Functional).\n    \n    Input 0 of layer \"conv2d_22\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 128, 174, 1)\n    \n    Call arguments received by layer \"model_3\" \"                 f\"(type Functional):\n      • inputs=('tf.Tensor(shape=(None, 40, 174, 1), dtype=float32)', 'tf.Tensor(shape=(None, 128, 174, 1), dtype=float32)')\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m X_test_mels \u001b[39m=\u001b[39m X_test_mels\u001b[39m.\u001b[39mreshape(\u001b[39mlist\u001b[39m(X_test_mels\u001b[39m.\u001b[39mshape) \u001b[39m+\u001b[39m [\u001b[39m1\u001b[39m])\n\u001b[0;32m     31\u001b[0m model \u001b[39m=\u001b[39m multi_input_cnn(input_shape_mfcc, input_shape_mels, num_classes)\n\u001b[1;32m---> 33\u001b[0m model\u001b[39m.\u001b[39;49mfit([X_train_mfcc, X_train_mels], y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict([X_test_mfcc, X_test_mels])\n\u001b[0;32m     36\u001b[0m predicted_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0jq0ve1v.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model_3\" \"                 f\"(type Functional).\n    \n    Input 0 of layer \"conv2d_22\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 128, 174, 1)\n    \n    Call arguments received by layer \"model_3\" \"                 f\"(type Functional):\n      • inputs=('tf.Tensor(shape=(None, 40, 174, 1), dtype=float32)', 'tf.Tensor(shape=(None, 128, 174, 1), dtype=float32)')\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "fold_accuracies = []\n",
    "early_stopping = EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.0001, monitor='val_loss')\n",
    "input_shape_mfcc = (40, 174, 1)\n",
    "input_shape_mels = (128, 174, 3)\n",
    "num_classes = 10\n",
    "for i in range(1, 11):  # 10-fold\n",
    "    print(f\"Processing fold {i}\")\n",
    "    test_data = metadata[metadata['fold'] == i]\n",
    "    train_data = metadata[metadata['fold'] != i]\n",
    "\n",
    "    X_train_mfcc = np.array([np.load(f'mfcc/{filename}.npy') for filename in train_data['slice_file_name']])\n",
    "    X_test_mfcc = np.array([np.load(f'mfcc/{filename}.npy') for filename in test_data['slice_file_name']])\n",
    "    X_train_mels = np.array([np.load(f'spectrograms/{filename}.npy') for filename in train_data['slice_file_name']])\n",
    "    X_test_mels = np.array([np.load(f'spectrograms/{filename}.npy') for filename in test_data['slice_file_name']])\n",
    "\n",
    "    y_train = np.array(train_data.classID.tolist())\n",
    "    y_test = np.array(test_data.classID.tolist())\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train = to_categorical(le.fit_transform(y_train))\n",
    "    y_test = to_categorical(le.fit_transform(y_test))\n",
    "\n",
    "    X_train_mfcc = X_train_mfcc.reshape(list(X_train_mfcc.shape) + [1])\n",
    "    X_test_mfcc = X_test_mfcc.reshape(list(X_test_mfcc.shape) + [1])\n",
    "    X_train_mels = X_train_mels.reshape(list(X_train_mels.shape) + [1])\n",
    "    X_test_mels = X_test_mels.reshape(list(X_test_mels.shape) + [1])\n",
    "\n",
    "    model = multi_input_cnn(input_shape_mfcc, input_shape_mels, num_classes)\n",
    "\n",
    "    model.fit([X_train_mfcc, X_train_mels], y_train, epochs=50, batch_size=256, verbose=1)\n",
    "\n",
    "    predictions = model.predict([X_test_mfcc, X_test_mels])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    fold_accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    print(f\"Accuracy for fold {i}: {fold_accuracy}\")\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "print(f\"10-fold cross validation accuracy: {np.mean(fold_accuracies)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fold_accuracies = []\n",
    "\n",
    "# Loading MFCC features from the CSV file\n",
    "features_df = pd.read_csv('mfcc.csv')\n",
    "\n",
    "for i in range(1, 11):  # 10-fold\n",
    "    print(f\"Processing fold {i}\")\n",
    "    test_data = metadata[metadata['fold'] == i]\n",
    "    train_data = metadata[metadata['fold'] != i]\n",
    "\n",
    "    X_train_mfcc = np.array([np.load(f'mfcc/{filename}.npy') for filename in train_data['slice_file_name']])\n",
    "    X_test_mfcc = np.array([np.load(f'mfcc/{filename}.npy') for filename in test_data['slice_file_name']])\n",
    "    X_train_mels = np.array([np.load(f'spectrograms/{filename}.npy') for filename in train_data['slice_file_name']])\n",
    "    X_test_mels = np.array([np.load(f'spectrograms/{filename}.npy') for filename in test_data['slice_file_name']])\n",
    "\n",
    "    y_train = np.array(train_data.classID.tolist())\n",
    "    y_test = np.array(test_data.classID.tolist())\n",
    "\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train = to_categorical(le.fit_transform(y_train))\n",
    "    y_test = to_categorical(le.fit_transform(y_test))\n",
    "\n",
    "    print(X_train)\n",
    "    X_train = X_train.reshape(X_train.shape[0], 40, 174, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 40, 174, 1)\n",
    "\n",
    "    model = cnn()\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=256, verbose=1)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "    fold_accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    print(f\"Accuracy for fold {i}: {fold_accuracy}\")\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "print(f\"10-fold cross validation accuracy: {np.mean(fold_accuracies)}\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
