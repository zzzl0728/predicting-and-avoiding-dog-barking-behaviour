{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "def extract_mfcc(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    #audio = random_segment(audio, sample_rate,2)\n",
    "    centered_waveform = audio - np.mean(audio)\n",
    "    normalized_waveform = centered_waveform / np.std(centered_waveform)\n",
    "    if not np.isfinite(normalized_waveform).all():\n",
    "        normalized_waveform = np.nan_to_num(normalized_waveform) \n",
    "    mfccs = librosa.feature.mfcc(y=normalized_waveform, sr=sample_rate, n_mfcc=40)\n",
    "    return mfccs\n",
    "\n",
    "def extract_melspectrogram(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    #audio = random_segment(audio, sample_rate,2)\n",
    "    centered_waveform = audio - np.mean(audio)\n",
    "    normalized_waveform = centered_waveform / np.std(centered_waveform)\n",
    "    if not np.isfinite(normalized_waveform).all():\n",
    "        normalized_waveform = np.nan_to_num(normalized_waveform) \n",
    "    melspectrogram = librosa.feature.melspectrogram(y=normalized_waveform, sr=sample_rate)\n",
    "    return melspectrogram\n",
    "\n",
    "def random_segment(waveform,sr, duration):\n",
    "    max_start_time = len(waveform) - sr * duration\n",
    "    start_time = np.random.uniform(0, max_start_time)\n",
    "    end_time = start_time + sr * duration\n",
    "    segment = waveform[int(start_time):int(end_time)]\n",
    "    return segment\n",
    "\n",
    "def random_sample(waveform, sr, duration, threshold=0.01):\n",
    "    non_silent_intervals = librosa.effects.split(waveform, top_db=threshold)\n",
    "    sample_length = sr * duration\n",
    "    \n",
    "    if len(non_silent_intervals) == 0 or non_silent_intervals[-1][1] < sample_length:\n",
    "        max_start_idx = len(waveform) - sample_length\n",
    "        start_idx = np.random.randint(0, max_start_idx if max_start_idx > 0 else 1)\n",
    "    else:\n",
    "        longest_interval = max(non_silent_intervals, key=lambda interval: interval[1] - interval[0])\n",
    "        interval_length = longest_interval[1] - longest_interval[0]\n",
    "\n",
    "        if interval_length >= sample_length:\n",
    "            max_start_idx = longest_interval[1] - sample_length\n",
    "            start_idx = np.random.randint(longest_interval[0], max_start_idx)\n",
    "        else:\n",
    "            start_idx = longest_interval[0]\n",
    "\n",
    "    end_idx = start_idx + sample_length\n",
    "    segment = np.concatenate([waveform[start_idx:end_idx], np.zeros(max(0, sample_length - len(waveform[start_idx:end_idx])))])\n",
    "\n",
    "    return segment\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    file = 'ESC-50-master/audio/' + row['filename']\n",
    "    mfccs = extract_mfcc(file)\n",
    "    np.save(file.replace('.wav', '_preprocess_mfcc.npy'), mfccs)\n",
    "    \n",
    "    melspectrogram = extract_melspectrogram(file)\n",
    "    np.save(file.replace('.wav', '_preprocess_melspectrogram.npy'), melspectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read features\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "df['mfccs'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' + file.replace('.wav', '_mfcc.npy')))\n",
    "df['melspectrogram'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' +  file.replace('.wav', '_melspectrogram.npy')))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['mfccs', 'melspectrogram']], to_categorical(df['target']), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pre-processed features\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "df['mfccs'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' + file.replace('.wav', '_preprocess_mfcc.npy')))\n",
    "df['melspectrogram'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' +  file.replace('.wav', '_preprocess_melspectrogram.npy')))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['mfccs', 'melspectrogram']], to_categorical(df['target']), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    batch_size = x.shape[0]\n",
    "    lam = np.random.beta(alpha, alpha, batch_size)\n",
    "    index = np.random.permutation(batch_size)\n",
    "\n",
    "    mixed_x = lam.reshape(batch_size, 1, 1, 1) * x + (1 - lam).reshape(batch_size, 1, 1, 1) * x[index, :]\n",
    "    mixed_y = lam.reshape(batch_size, 1) * y + (1 - lam).reshape(batch_size, 1) * y[index, :]\n",
    "\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "x_train_mixed, y_train_mixed = mixup_data(x_train, y_train, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc visulisation\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "unique_classes = df['category'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(10, 5, figsize=(15, 30))  # adjust this to display 50 images in a manner you find suitable\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, category in enumerate(unique_classes):\n",
    "    sample_file = df[df['category'] == category].iloc[0]['filename']\n",
    "    file_path = f'ESC-50-master/audio/{sample_file}'\n",
    "    \n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    \n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=axs[i])\n",
    "    axs[i].set_title(category)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel visulisation\n",
    "unique_classes = df['category'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(10, 5, figsize=(15, 30)) \n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, category in enumerate(unique_classes):\n",
    "    sample_file = df[df['category'] == category].iloc[0]['filename']\n",
    "    file_path = f'ESC-50-master/audio/{sample_file}'\n",
    "    \n",
    "    y, sr = librosa.load(file_path)\n",
    "    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    \n",
    "    log_mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "    \n",
    "    librosa.display.specshow(log_mel_spect, sr=sr, x_axis='time', y_axis='mel', ax=axs[i])\n",
    "    axs[i].set_title(category)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_train['melspectrogram'].tolist():\n",
    "    print(np.array(i).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base mfcc\n",
    "# structure inspired from https://github.com/karolpiczak/paper-2015-esc-convnet/tree/master\n",
    "from keras import models, layers\n",
    "\n",
    "INPUTSHAPE = X_train['mfccs'].iloc[0].shape[0], X_train['melspectrogram'].iloc[0].shape[1], 1\n",
    "filter_count = 64\n",
    "class_count = 50\n",
    "model1 = models.Sequential([\n",
    "    layers.Conv2D(filter_count, kernel_size=(3, 3), activation='relu', input_shape=INPUTSHAPE, padding='valid'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    layers.Conv2D(filter_count, kernel_size=(3, 3), activation='relu', padding='valid'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(5000, activation='relu'),\n",
    "    layers.Dense(5000, activation='relu'),\n",
    "    layers.Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model1.summary()\n",
    "model1.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=10, batch_size=32)\n",
    "\n",
    "X_test_reshaped = np.array([i[..., np.newaxis] for i in X_test['mfccs'].tolist()])\n",
    "y_pred = model1.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfcc structure from https://www.kaggle.com/code/kalibrahim/audio-processing-features-cnn-training\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "input1 = Input(shape=(X_train['mfccs'].iloc[0].shape[0], X_train['mfccs'].iloc[0].shape[1], 1))\n",
    "\n",
    "mfcc_model = models.Sequential([\n",
    "    layers.Conv2D(32 , (3,3),activation = 'relu',padding='valid', input_shape = (X_train['mfccs'].iloc[0].shape[0], X_train['mfccs'].iloc[0].shape[1], 1)),  \n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512 , activation = 'relu'),\n",
    "    layers.Dense(50 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "mfcc_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "print(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]).shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)  # stops after 3 epochs of no improvement\n",
    "\n",
    "res = mfcc_model.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=40, batch_size=8)\n",
    "#res = mfcc_model.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=40, batch_size=8, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "X_test_reshaped = np.array([i[..., np.newaxis] for i in X_test['mfccs'].tolist()])\n",
    "y_pred = mfcc_model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "mfcc_model.save('mfcc_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "mels_model = models.Sequential([\n",
    "    layers.Conv2D(32 , (3,3),activation = 'relu',padding='valid', input_shape = (X_train['melspectrogram'].iloc[0].shape[0], X_train['melspectrogram'].iloc[0].shape[1], 1)),  \n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512 , activation = 'relu'),\n",
    "    layers.Dense(50 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "mels_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "print(np.array([i[..., np.newaxis] for i in X_train['melspectrogram'].tolist()]).shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)  # stops after 3 epochs of no improvement\n",
    "\n",
    "res = mels_model.fit(np.array([i[..., np.newaxis] for i in X_train['melspectrogram'].tolist()]), y_train, epochs=40, batch_size=8)\n",
    "#res = mfcc_model.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=40, batch_size=8, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "X_test_reshaped = np.array([i[..., np.newaxis] for i in X_test['melspectrogram'].tolist()])\n",
    "y_pred = mels_model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "mfcc_model.save('mels_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.6660 - val_loss: 0.5734\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.4145 - val_loss: 0.1837\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0983 - val_loss: 0.2428\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1155 - val_loss: 0.2097\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0877 - val_loss: 0.1172\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0556 - val_loss: 0.0756\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.0507 - val_loss: 0.0643\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0447 - val_loss: 0.0539\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.0393 - val_loss: 0.0449\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0324 - val_loss: 0.0318\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.0307 - val_loss: 0.0310\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0303 - val_loss: 0.0310\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0302 - val_loss: 0.0308\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0299 - val_loss: 0.0309\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0295 - val_loss: 0.0315\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.0292 - val_loss: 0.0317\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0288 - val_loss: 0.0311\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0282 - val_loss: 0.0303\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0276 - val_loss: 0.0297\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0269 - val_loss: 0.0291\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0263 - val_loss: 0.0278\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0257 - val_loss: 0.0270\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0252 - val_loss: 0.0260\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0248 - val_loss: 0.0251\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0241 - val_loss: 0.0235\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.0236 - val_loss: 0.0224\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0235 - val_loss: 0.0218\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0233 - val_loss: 0.0214\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0228 - val_loss: 0.0202\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0227 - val_loss: 0.0200\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0226 - val_loss: 0.0199\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0226 - val_loss: 0.0198\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0225 - val_loss: 0.0195\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0224 - val_loss: 0.0194\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0224 - val_loss: 0.0192\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0223 - val_loss: 0.0189\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0223 - val_loss: 0.0188\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0222 - val_loss: 0.0187\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0222 - val_loss: 0.0185\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0221 - val_loss: 0.0184\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0221 - val_loss: 0.0183\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 31s 4s/step - loss: 0.0220 - val_loss: 0.0182\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0220 - val_loss: 0.0179\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0220 - val_loss: 0.0178\n",
      "50/50 [==============================] - 4s 77ms/step\n",
      "13/13 [==============================] - 1s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# assume X_train_mel and X_test_mel are your Mel spectrogram features for training and testing\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# reshape data for scaling\n",
    "X_train_mel_reshaped = X_train_mel.reshape((-1, X_train_mel.shape[-2]*X_train_mel.shape[-1]))\n",
    "X_test_mel_reshaped = X_test_mel.reshape((-1, X_test_mel.shape[-2]*X_test_mel.shape[-1]))\n",
    "\n",
    "# apply MinMaxScaler\n",
    "X_train_mel_scaled = scaler.fit_transform(X_train_mel_reshaped)\n",
    "X_test_mel_scaled = scaler.transform(X_test_mel_reshaped)\n",
    "\n",
    "# reshape data back to original shape\n",
    "X_train_mel_scaled = X_train_mel_scaled.reshape((-1, X_train_mel.shape[1], X_train_mel.shape[2], 1))\n",
    "X_test_mel_scaled = X_test_mel_scaled.reshape((-1, X_test_mel.shape[1], X_test_mel.shape[2], 1))\n",
    "\n",
    "# define the convolutional autoencoder\n",
    "input_img = Input(shape=(X_train_mel_scaled.shape[1], X_train_mel_scaled.shape[2], 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder\n",
    "autoencoder.fit(X_train_mel_scaled, X_train_mel_scaled, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test_mel_scaled, X_test_mel_scaled))\n",
    "\n",
    "# use the encoder part of the autoencoder to reduce the dimension of Mel spectrogram\n",
    "encoder = Model(input_img, encoded)\n",
    "X_train_mel_encoded = encoder.predict(X_train_mel_scaled)\n",
    "X_test_mel_encoded = encoder.predict(X_test_mel_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_mel_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(X_train[\u001b[39m'\u001b[39m\u001b[39mmfccs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(X_train_mel_encoded\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(X_train[\u001b[39m'\u001b[39m\u001b[39mmfccs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(X_train_mel_encoded\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_mel_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train['mfccs'].shape)\n",
    "print(X_train_mel_encoded.shape)\n",
    "print(X_train['mfccs'].iloc[0].shape)\n",
    "    \n",
    "print(X_train_mel_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Concatenate\n\u001b[0;32m      4\u001b[0m \u001b[39m# mfcc input\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m mfcc_input \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(X_train[\u001b[39m'\u001b[39m\u001b[39mmfccs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X_train[\u001b[39m'\u001b[39m\u001b[39mmfccs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[0;32m      7\u001b[0m mfcc_x \u001b[39m=\u001b[39m Conv2D(\u001b[39m32\u001b[39m , (\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m)(mfcc_input)  \n\u001b[0;32m      8\u001b[0m mfcc_x \u001b[39m=\u001b[39m MaxPooling2D(\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m)(mfcc_x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Concatenate\n",
    "autoencoder = load('autoencoder.h5')\n",
    "# mfcc input\n",
    "mfcc_input = Input(shape=(X_train['mfccs'].iloc[0].shape[0], X_train['mfccs'].iloc[0].shape[1], 1))\n",
    "\n",
    "mfcc_x = Conv2D(32 , (3,3),activation = 'relu',padding='valid')(mfcc_input)  \n",
    "mfcc_x = MaxPooling2D(2, padding='same')(mfcc_x)\n",
    "mfcc_x = Conv2D(128, (3,3), activation='relu',padding='valid')(mfcc_x)\n",
    "mfcc_x = MaxPooling2D(2, padding='same')(mfcc_x)\n",
    "mfcc_x = Dropout(0.3)(mfcc_x)\n",
    "mfcc_x = Conv2D(128, (3,3), activation='relu',padding='valid')(mfcc_x)\n",
    "mfcc_x = MaxPooling2D(2, padding='same')(mfcc_x)\n",
    "mfcc_x = Dropout(0.3)(mfcc_x)\n",
    "mfcc_output = GlobalAveragePooling2D()(mfcc_x)\n",
    "\n",
    "# melspectrogram input\n",
    "mel_input = Input(shape=X_train_mel_encoded.shape[1:])\n",
    "mel_x = Flatten()(mel_input)\n",
    "mel_output = Dense(128, activation='relu')(mel_x)\n",
    "\n",
    "combined = Concatenate()([mfcc_output, mel_output])\n",
    "fc = Dense(512 , activation = 'relu')(combined)\n",
    "\n",
    "output = Dense(50 , activation = 'softmax')(fc)\n",
    "\n",
    "multi_input_model = Model(inputs=[mfcc_input, mel_input], outputs=output)\n",
    "\n",
    "#multi_input_model.fit([X_train['mfccs'], X_train_mel_encoded], y_train, epochs=40, batch_size=8)\n",
    "multi_input_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "X_train_mfccs = np.array(X_train['mfccs'].tolist())\n",
    "multi_input_model.fit([X_train_mfccs, X_train_mel_encoded], y_train, epochs=40, batch_size=8)\n",
    "\n",
    "X_test_mel_encoded = encoder.predict(X_test_mel_scaled)\n",
    "y_pred = multi_input_model.predict([X_test['mfccs'], X_test_mel_encoded])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_test_mfccs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_test[\u001b[39m'\u001b[39m\u001b[39mmfccs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m      4\u001b[0m y_pred \u001b[39m=\u001b[39m multi_input_model\u001b[39m.\u001b[39mpredict([X_test_mfccs, X_test_mel_encoded])\n\u001b[0;32m      5\u001b[0m y_pred_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "X_test_mfccs = np.array(X_test['mfccs'].tolist())\n",
    "y_pred = multi_input_model.predict([X_test_mfccs, X_test_mel_encoded])\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Extract precision, recall, and F1-score for each class\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m report \u001b[39m=\u001b[39m  classification_report(y_test_labels, y_pred_labels)\n\u001b[0;32m      3\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m))\n\u001b[0;32m      4\u001b[0m precision \u001b[39m=\u001b[39m [report[\u001b[39mstr\u001b[39m(c)][\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m classes]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract precision, recall, and F1-score for each class\n",
    "report =  classification_report(y_test_labels, y_pred_labels)\n",
    "classes = list(range(50))\n",
    "precision = [report[str(c)]['precision'] for c in classes]\n",
    "recall = [report[str(c)]['recall'] for c in classes]\n",
    "f1_score = [report[str(c)]['f1-score'] for c in classes]\n",
    "\n",
    "# Generate the x-axis positions for the bars\n",
    "x_pos = np.arange(len(classes))\n",
    "\n",
    "# Plot the precision, recall, and F1-score for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_pos, precision, width=0.25, label='Precision')\n",
    "plt.bar(x_pos + 0.25, recall, width=0.25, label='Recall')\n",
    "plt.bar(x_pos + 0.5, f1_score, width=0.25, label='F1-Score')\n",
    "\n",
    "# Set the x-axis labels and tick positions\n",
    "plt.xticks(x_pos + 0.25, classes, rotation='vertical')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 40, 216, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 38, 214, 32)  320         ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_52 (MaxPooling2D  (None, 19, 107, 32)  0          ['conv2d_61[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 105, 128  36992       ['max_pooling2d_52[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_53 (MaxPooling2D  (None, 9, 53, 128)  0           ['conv2d_62[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 9, 53, 128)   0           ['max_pooling2d_53[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 51, 128)   147584      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_54 (MaxPooling2D  (None, 4, 26, 128)  0           ['conv2d_63[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 32, 54, 32)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 4, 26, 128)   0           ['max_pooling2d_54[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 55296)        0           ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 128)         0           ['dropout_17[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 128)          7078016     ['flatten_12[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256)          0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 512)          131584      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 50)           25650       ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,420,146\n",
      "Trainable params: 7,420,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "multi_input_model.summary()\n",
    "multi_input_model.save('multi_input_model.h5')\n",
    "plot_model(multi_input_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "def extract(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    centered_waveform = audio - np.mean(audio)\n",
    "    normalized_waveform = centered_waveform / np.std(centered_waveform)\n",
    "    if not np.isfinite(normalized_waveform).all():\n",
    "        normalized_waveform = np.nan_to_num(normalized_waveform) \n",
    "    return normalized_waveform\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    file = 'ESC-50-master/audio/' + row['filename']\n",
    "    audio = extract(file)\n",
    "    row['audio_wave'] = audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mESC-50-master/audio/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m embeddings \u001b[39m=\u001b[39m extract_features(file)\n\u001b[1;32m---> 28\u001b[0m df\u001b[39m.\u001b[39mloc[index, \u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "def extract_features(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    centered_waveform = audio - np.mean(audio)\n",
    "    normalized_waveform = centered_waveform / np.std(centered_waveform)\n",
    "    \n",
    "    normalized_waveform = np.clip(normalized_waveform, -1, 1)\n",
    "    \n",
    "    if len(normalized_waveform) < int(sample_rate):\n",
    "        pad_len = int(sample_rate) - len(normalized_waveform)\n",
    "        normalized_waveform = np.pad(normalized_waveform, (0, pad_len), 'constant')\n",
    "\n",
    "    normalized_waveform = tf.convert_to_tensor(normalized_waveform, dtype=tf.float32)\n",
    "    \n",
    "    scores, embeddings, spectrogram = yamnet_model(normalized_waveform)\n",
    "    \n",
    "    return embeddings[-1, :].numpy()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    file = 'ESC-50-master/audio/' + row['filename']\n",
    "    embeddings = extract_features(file)\n",
    "    df.loc[index, 'embeddings'] = embeddings.numpy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embeddings = np.array(df_train['embeddings'].tolist())\n",
    "X_test_embeddings = np.array(df_test['embeddings'].tolist())\n",
    "\n",
    "input2 = Input(shape=(1024,))\n",
    "\n",
    "yamnet_model = models.Sequential([\n",
    "    layers.Dense(512 , activation = 'relu', input_shape=(1024,)),\n",
    "    layers.Dense(50 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "yamnet_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "res = yamnet_model.fit(X_train_embeddings, y_train, epochs=40, batch_size=8, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "y_pred = yamnet_model.predict(X_test_embeddings)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "yamnet_model.save('yamnet_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
