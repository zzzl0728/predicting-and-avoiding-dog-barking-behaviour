{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "def extract_mfcc(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    #audio = random_segment(audio, sample_rate,2)\n",
    "    centered_waveform = audio - np.mean(audio)\n",
    "    normalized_waveform = centered_waveform / np.std(centered_waveform)\n",
    "    if not np.isfinite(normalized_waveform).all():\n",
    "        normalized_waveform = np.nan_to_num(normalized_waveform) \n",
    "    mfccs = librosa.feature.mfcc(y=normalized_waveform, sr=sample_rate, n_mfcc=40)\n",
    "    return mfccs\n",
    "\n",
    "def extract_melspectrogram(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    #audio = random_segment(audio, sample_rate,2)\n",
    "    centered_waveform = audio - np.mean(audio)\n",
    "    normalized_waveform = centered_waveform / np.std(centered_waveform)\n",
    "    if not np.isfinite(normalized_waveform).all():\n",
    "        normalized_waveform = np.nan_to_num(normalized_waveform) \n",
    "    melspectrogram = librosa.feature.melspectrogram(y=normalized_waveform, sr=sample_rate)\n",
    "    return melspectrogram\n",
    "\n",
    "def random_segment(waveform,sr, duration):\n",
    "    max_start_time = len(waveform) - sr * duration\n",
    "    start_time = np.random.uniform(0, max_start_time)\n",
    "    end_time = start_time + sr * duration\n",
    "    segment = waveform[int(start_time):int(end_time)]\n",
    "    return segment\n",
    "\n",
    "def random_sample(waveform, sr, duration, threshold=0.01):\n",
    "    non_silent_intervals = librosa.effects.split(waveform, top_db=threshold)\n",
    "    sample_length = sr * duration\n",
    "    \n",
    "    if len(non_silent_intervals) == 0 or non_silent_intervals[-1][1] < sample_length:\n",
    "        max_start_idx = len(waveform) - sample_length\n",
    "        start_idx = np.random.randint(0, max_start_idx if max_start_idx > 0 else 1)\n",
    "    else:\n",
    "        longest_interval = max(non_silent_intervals, key=lambda interval: interval[1] - interval[0])\n",
    "        interval_length = longest_interval[1] - longest_interval[0]\n",
    "\n",
    "        if interval_length >= sample_length:\n",
    "            max_start_idx = longest_interval[1] - sample_length\n",
    "            start_idx = np.random.randint(longest_interval[0], max_start_idx)\n",
    "        else:\n",
    "            start_idx = longest_interval[0]\n",
    "\n",
    "    end_idx = start_idx + sample_length\n",
    "    segment = np.concatenate([waveform[start_idx:end_idx], np.zeros(max(0, sample_length - len(waveform[start_idx:end_idx])))])\n",
    "\n",
    "    return segment\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    file = 'ESC-50-master/audio/' + row['filename']\n",
    "    mfccs = extract_mfcc(file)\n",
    "    np.save(file.replace('.wav', '_preprocess_mfcc.npy'), mfccs)\n",
    "    \n",
    "    melspectrogram = extract_melspectrogram(file)\n",
    "    np.save(file.replace('.wav', '_preprocess_melspectrogram.npy'), melspectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read features\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "df['mfccs'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' + file.replace('.wav', '_mfcc.npy')))\n",
    "df['melspectrogram'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' +  file.replace('.wav', '_melspectrogram.npy')))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['mfccs', 'melspectrogram']], to_categorical(df['target']), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pre-processed features\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "df['mfccs'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' + file.replace('.wav', '_preprocess_mfcc.npy')))\n",
    "df['melspectrogram'] = df['filename'].apply(lambda file: np.load('ESC-50-master/audio/' +  file.replace('.wav', '_preprocess_melspectrogram.npy')))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['mfccs', 'melspectrogram']], to_categorical(df['target']), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    batch_size = x.shape[0]\n",
    "    lam = np.random.beta(alpha, alpha, batch_size)\n",
    "    index = np.random.permutation(batch_size)\n",
    "\n",
    "    mixed_x = lam.reshape(batch_size, 1, 1, 1) * x + (1 - lam).reshape(batch_size, 1, 1, 1) * x[index, :]\n",
    "    mixed_y = lam.reshape(batch_size, 1) * y + (1 - lam).reshape(batch_size, 1) * y[index, :]\n",
    "\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "x_train_mixed, y_train_mixed = mixup_data(x_train, y_train, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc visulisation\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
    "\n",
    "unique_classes = df['category'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(10, 5, figsize=(15, 30))  # adjust this to display 50 images in a manner you find suitable\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, category in enumerate(unique_classes):\n",
    "    sample_file = df[df['category'] == category].iloc[0]['filename']\n",
    "    file_path = f'ESC-50-master/audio/{sample_file}'\n",
    "    \n",
    "    y, sr = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    \n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=axs[i])\n",
    "    axs[i].set_title(category)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mel visulisation\n",
    "unique_classes = df['category'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(10, 5, figsize=(15, 30)) \n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, category in enumerate(unique_classes):\n",
    "    sample_file = df[df['category'] == category].iloc[0]['filename']\n",
    "    file_path = f'ESC-50-master/audio/{sample_file}'\n",
    "    \n",
    "    y, sr = librosa.load(file_path)\n",
    "    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    \n",
    "    log_mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "    \n",
    "    librosa.display.specshow(log_mel_spect, sr=sr, x_axis='time', y_axis='mel', ax=axs[i])\n",
    "    axs[i].set_title(category)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n",
      "(128, 216)\n"
     ]
    }
   ],
   "source": [
    "for i in X_train['melspectrogram'].tolist():\n",
    "    print(np.array(i).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base mfcc\n",
    "# structure inspired from https://github.com/karolpiczak/paper-2015-esc-convnet/tree/master\n",
    "from keras import models, layers\n",
    "\n",
    "INPUTSHAPE = X_train['mfccs'].iloc[0].shape[0], X_train['melspectrogram'].iloc[0].shape[1], 1\n",
    "filter_count = 64\n",
    "class_count = 50\n",
    "model1 = models.Sequential([\n",
    "    layers.Conv2D(filter_count, kernel_size=(3, 3), activation='relu', input_shape=INPUTSHAPE, padding='valid'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    layers.Conv2D(filter_count, kernel_size=(3, 3), activation='relu', padding='valid'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(5000, activation='relu'),\n",
    "    layers.Dense(5000, activation='relu'),\n",
    "    layers.Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model1.summary()\n",
    "model1.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=10, batch_size=32)\n",
    "\n",
    "X_test_reshaped = np.array([i[..., np.newaxis] for i in X_test['mfccs'].tolist()])\n",
    "y_pred = model1.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 40, 216, 1)\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 9s 40ms/step - loss: 3.5924 - acc: 0.0812\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 2.8401 - acc: 0.2175\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 2.3987 - acc: 0.2875\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 2.0303 - acc: 0.3988\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 11s 57ms/step - loss: 1.7499 - acc: 0.4775\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.5435 - acc: 0.5375\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 1.3683 - acc: 0.5831\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 1.2302 - acc: 0.6131\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 1.0903 - acc: 0.6587\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 12s 57ms/step - loss: 0.9355 - acc: 0.7019\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.9275 - acc: 0.7088\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.7239 - acc: 0.7738\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.6514 - acc: 0.7950\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.6140 - acc: 0.7906\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.5403 - acc: 0.8125\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4177 - acc: 0.8637\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4222 - acc: 0.8619\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4812 - acc: 0.8600\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3043 - acc: 0.8956\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.2705 - acc: 0.9200\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.3520 - acc: 0.8825\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.2916 - acc: 0.9056\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4699 - acc: 0.8606\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.2175 - acc: 0.9337\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.2249 - acc: 0.9306\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2510 - acc: 0.9169\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.1373 - acc: 0.9550\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.2386 - acc: 0.9369\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 9s 42ms/step - loss: 0.3655 - acc: 0.8888\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.2955 - acc: 0.9231\n",
      "13/13 [==============================] - 1s 46ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        11\n",
      "           1       0.75      0.75      0.75         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.80      0.67      0.73         6\n",
      "           4       0.62      0.71      0.67         7\n",
      "           5       0.64      0.64      0.64        14\n",
      "           6       0.67      0.50      0.57         8\n",
      "           7       0.75      0.43      0.55         7\n",
      "           8       0.54      0.70      0.61        10\n",
      "           9       0.72      0.93      0.81        14\n",
      "          10       0.60      0.75      0.67         8\n",
      "          11       0.64      0.78      0.70         9\n",
      "          12       0.67      0.67      0.67         6\n",
      "          13       0.50      0.71      0.59         7\n",
      "          14       0.71      0.50      0.59        10\n",
      "          15       0.67      0.33      0.44         6\n",
      "          16       0.55      0.86      0.67         7\n",
      "          17       0.60      1.00      0.75         9\n",
      "          18       1.00      0.58      0.74        12\n",
      "          19       0.86      0.55      0.67        11\n",
      "          20       0.71      1.00      0.83         5\n",
      "          21       0.75      0.38      0.50         8\n",
      "          22       0.69      0.90      0.78        10\n",
      "          23       0.60      0.50      0.55         6\n",
      "          24       0.36      0.57      0.44         7\n",
      "          25       0.50      0.75      0.60         8\n",
      "          26       0.67      0.22      0.33         9\n",
      "          27       0.75      0.43      0.55         7\n",
      "          28       0.75      1.00      0.86         6\n",
      "          29       0.11      0.50      0.18         2\n",
      "          30       1.00      0.89      0.94         9\n",
      "          31       0.40      0.57      0.47         7\n",
      "          32       0.88      0.47      0.61        15\n",
      "          33       0.33      0.14      0.20         7\n",
      "          34       1.00      0.57      0.73         7\n",
      "          35       0.45      0.50      0.48        10\n",
      "          36       0.44      0.67      0.53         6\n",
      "          37       1.00      0.56      0.71         9\n",
      "          38       0.57      0.57      0.57         7\n",
      "          39       0.40      1.00      0.57         6\n",
      "          40       0.30      0.50      0.37         6\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.75      0.60      0.67         5\n",
      "          43       0.83      0.56      0.67         9\n",
      "          44       0.45      0.56      0.50         9\n",
      "          45       0.67      0.50      0.57         8\n",
      "          46       0.33      0.17      0.22         6\n",
      "          47       1.00      0.38      0.55         8\n",
      "          48       0.71      0.50      0.59        10\n",
      "          49       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.61       400\n",
      "   macro avg       0.63      0.60      0.58       400\n",
      "weighted avg       0.66      0.61      0.61       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mfcc structure from https://www.kaggle.com/code/kalibrahim/audio-processing-features-cnn-training\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "input1 = Input(shape=(X_train['mfccs'].iloc[0].shape[0], X_train['mfccs'].iloc[0].shape[1], 1))\n",
    "\n",
    "mfcc_model = models.Sequential([\n",
    "    layers.Conv2D(32 , (3,3),activation = 'relu',padding='valid', input_shape = (X_train['mfccs'].iloc[0].shape[0], X_train['mfccs'].iloc[0].shape[1], 1)),  \n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512 , activation = 'relu'),\n",
    "    layers.Dense(50 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "mfcc_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "print(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]).shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)  # stops after 3 epochs of no improvement\n",
    "\n",
    "res = mfcc_model.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=40, batch_size=8)\n",
    "#res = mfcc_model.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=40, batch_size=8, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "X_test_reshaped = np.array([i[..., np.newaxis] for i in X_test['mfccs'].tolist()])\n",
    "y_pred = mfcc_model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "mfcc_model.save('mfcc_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_103 (Conv2D)         (None, 38, 214, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 19, 107, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 17, 105, 128)      36992     \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 9, 53, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 9, 53, 128)        0         \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 7, 51, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_84 (MaxPoolin  (None, 4, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 4, 26, 128)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d_24  (None, 128)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 50)                25650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276,594\n",
      "Trainable params: 276,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mfcc_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "mels_model = models.Sequential([\n",
    "    layers.Conv2D(32 , (3,3),activation = 'relu',padding='valid', input_shape = (X_train['melspectrogram'].iloc[0].shape[0], X_train['melspectrogram'].iloc[0].shape[1], 1)),  \n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "    layers.MaxPooling2D(2, padding='same'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512 , activation = 'relu'),\n",
    "    layers.Dense(50 , activation = 'softmax')\n",
    "])\n",
    "\n",
    "mels_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "\n",
    "print(np.array([i[..., np.newaxis] for i in X_train['melspectrogram'].tolist()]).shape)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)  # stops after 3 epochs of no improvement\n",
    "\n",
    "res = mels_model.fit(np.array([i[..., np.newaxis] for i in X_train['melspectrogram'].tolist()]), y_train, epochs=40, batch_size=8)\n",
    "#res = mfcc_model.fit(np.array([i[..., np.newaxis] for i in X_train['mfccs'].tolist()]), y_train, epochs=40, batch_size=8, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "X_test_reshaped = np.array([i[..., np.newaxis] for i in X_test['melspectrogram'].tolist()])\n",
    "y_pred = mels_model.predict(X_test_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "mfcc_model.save('mels_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.6660 - val_loss: 0.5734\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.4145 - val_loss: 0.1837\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0983 - val_loss: 0.2428\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.1155 - val_loss: 0.2097\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0877 - val_loss: 0.1172\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0556 - val_loss: 0.0756\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.0507 - val_loss: 0.0643\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0447 - val_loss: 0.0539\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.0393 - val_loss: 0.0449\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0354 - val_loss: 0.0352\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0324 - val_loss: 0.0318\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.0307 - val_loss: 0.0310\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0303 - val_loss: 0.0310\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0302 - val_loss: 0.0308\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0299 - val_loss: 0.0309\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0295 - val_loss: 0.0315\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.0292 - val_loss: 0.0317\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0288 - val_loss: 0.0311\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0282 - val_loss: 0.0303\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0276 - val_loss: 0.0297\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0269 - val_loss: 0.0291\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0263 - val_loss: 0.0278\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.0257 - val_loss: 0.0270\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0252 - val_loss: 0.0260\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0248 - val_loss: 0.0251\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0241 - val_loss: 0.0235\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.0236 - val_loss: 0.0224\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0235 - val_loss: 0.0218\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0233 - val_loss: 0.0214\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0231 - val_loss: 0.0210\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0229 - val_loss: 0.0204\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0228 - val_loss: 0.0202\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0227 - val_loss: 0.0200\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0226 - val_loss: 0.0199\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0226 - val_loss: 0.0198\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0225 - val_loss: 0.0195\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0224 - val_loss: 0.0194\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0224 - val_loss: 0.0192\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0223 - val_loss: 0.0189\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0223 - val_loss: 0.0188\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0222 - val_loss: 0.0187\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0222 - val_loss: 0.0185\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0221 - val_loss: 0.0184\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0221 - val_loss: 0.0183\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 31s 4s/step - loss: 0.0220 - val_loss: 0.0182\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0220 - val_loss: 0.0179\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0220 - val_loss: 0.0178\n",
      "50/50 [==============================] - 4s 77ms/step\n",
      "13/13 [==============================] - 1s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# assume X_train_mel and X_test_mel are your Mel spectrogram features for training and testing\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# reshape data for scaling\n",
    "X_train_mel_reshaped = X_train_mel.reshape((-1, X_train_mel.shape[-2]*X_train_mel.shape[-1]))\n",
    "X_test_mel_reshaped = X_test_mel.reshape((-1, X_test_mel.shape[-2]*X_test_mel.shape[-1]))\n",
    "\n",
    "# apply MinMaxScaler\n",
    "X_train_mel_scaled = scaler.fit_transform(X_train_mel_reshaped)\n",
    "X_test_mel_scaled = scaler.transform(X_test_mel_reshaped)\n",
    "\n",
    "# reshape data back to original shape\n",
    "X_train_mel_scaled = X_train_mel_scaled.reshape((-1, X_train_mel.shape[1], X_train_mel.shape[2], 1))\n",
    "X_test_mel_scaled = X_test_mel_scaled.reshape((-1, X_test_mel.shape[1], X_test_mel.shape[2], 1))\n",
    "\n",
    "# define the convolutional autoencoder\n",
    "input_img = Input(shape=(X_train_mel_scaled.shape[1], X_train_mel_scaled.shape[2], 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder\n",
    "autoencoder.fit(X_train_mel_scaled, X_train_mel_scaled, epochs=50, batch_size=256, shuffle=True, validation_data=(X_test_mel_scaled, X_test_mel_scaled))\n",
    "\n",
    "# use the encoder part of the autoencoder to reduce the dimension of Mel spectrogram\n",
    "encoder = Model(input_img, encoded)\n",
    "X_train_mel_encoded = encoder.predict(X_train_mel_scaled)\n",
    "X_test_mel_encoded = encoder.predict(X_test_mel_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n",
      "(1600, 32, 54, 32)\n",
      "(40, 216)\n",
      "(1600, 32, 54, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train['mfccs'].shape)\n",
    "print(X_train_mel_encoded.shape)\n",
    "print(X_train['mfccs'].iloc[0].shape)\n",
    "    \n",
    "print(X_train_mel_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "200/200 [==============================] - 18s 87ms/step - loss: 3.6809 - acc: 0.0650\n",
      "Epoch 2/40\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 2.8690 - acc: 0.2044\n",
      "Epoch 3/40\n",
      "200/200 [==============================] - 19s 93ms/step - loss: 2.4587 - acc: 0.2825\n",
      "Epoch 4/40\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 2.1623 - acc: 0.3631\n",
      "Epoch 5/40\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 1.8363 - acc: 0.4556\n",
      "Epoch 6/40\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 1.6212 - acc: 0.5244\n",
      "Epoch 7/40\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 1.4580 - acc: 0.5600\n",
      "Epoch 8/40\n",
      "200/200 [==============================] - 19s 95ms/step - loss: 1.3142 - acc: 0.6006\n",
      "Epoch 9/40\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 1.1705 - acc: 0.6369\n",
      "Epoch 10/40\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 1.0084 - acc: 0.6781\n",
      "Epoch 11/40\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 0.9157 - acc: 0.7125\n",
      "Epoch 12/40\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.7654 - acc: 0.7550\n",
      "Epoch 13/40\n",
      "200/200 [==============================] - 27s 134ms/step - loss: 0.7587 - acc: 0.7500\n",
      "Epoch 14/40\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.5618 - acc: 0.8131\n",
      "Epoch 15/40\n",
      "200/200 [==============================] - 26s 131ms/step - loss: 0.6027 - acc: 0.8069\n",
      "Epoch 16/40\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.5427 - acc: 0.8319\n",
      "Epoch 17/40\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.5276 - acc: 0.8388\n",
      "Epoch 18/40\n",
      "200/200 [==============================] - 25s 123ms/step - loss: 0.4096 - acc: 0.8687\n",
      "Epoch 19/40\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 0.4525 - acc: 0.8625\n",
      "Epoch 20/40\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.3147 - acc: 0.8994\n",
      "Epoch 21/40\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.3816 - acc: 0.8813\n",
      "Epoch 22/40\n",
      "200/200 [==============================] - 24s 118ms/step - loss: 0.2938 - acc: 0.9062\n",
      "Epoch 23/40\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.3469 - acc: 0.8894\n",
      "Epoch 24/40\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.2421 - acc: 0.9237\n",
      "Epoch 25/40\n",
      "200/200 [==============================] - 25s 124ms/step - loss: 0.3968 - acc: 0.8756\n",
      "Epoch 26/40\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 0.3570 - acc: 0.8894\n",
      "Epoch 27/40\n",
      "200/200 [==============================] - 26s 130ms/step - loss: 0.2300 - acc: 0.9250\n",
      "Epoch 28/40\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2294 - acc: 0.9306\n",
      "Epoch 29/40\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.1914 - acc: 0.9337\n",
      "Epoch 30/40\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.2873 - acc: 0.9156\n",
      "Epoch 31/40\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 0.1419 - acc: 0.9575\n",
      "Epoch 32/40\n",
      "200/200 [==============================] - 26s 127ms/step - loss: 0.0513 - acc: 0.9881\n",
      "Epoch 33/40\n",
      "200/200 [==============================] - 25s 125ms/step - loss: 0.2468 - acc: 0.9300\n",
      "Epoch 34/40\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.4449 - acc: 0.8744\n",
      "Epoch 35/40\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 0.2605 - acc: 0.9300\n",
      "Epoch 36/40\n",
      "200/200 [==============================] - 25s 126ms/step - loss: 0.1556 - acc: 0.9531\n",
      "Epoch 37/40\n",
      "200/200 [==============================] - 26s 129ms/step - loss: 0.1457 - acc: 0.9569\n",
      "Epoch 38/40\n",
      "200/200 [==============================] - 26s 128ms/step - loss: 0.2272 - acc: 0.9319\n",
      "Epoch 39/40\n",
      "200/200 [==============================] - 24s 122ms/step - loss: 0.1674 - acc: 0.9544\n",
      "Epoch 40/40\n",
      "200/200 [==============================] - 19s 96ms/step - loss: 0.1363 - acc: 0.9600\n",
      "13/13 [==============================] - 1s 57ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39m# make prediction\u001b[39;00m\n\u001b[0;32m     42\u001b[0m X_test_mel_encoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mpredict(X_test_mel_scaled)\n\u001b[1;32m---> 43\u001b[0m y_pred \u001b[39m=\u001b[39m multi_input_model\u001b[39m.\u001b[39;49mpredict([X_test[\u001b[39m'\u001b[39;49m\u001b[39mmfccs\u001b[39;49m\u001b[39m'\u001b[39;49m], X_test_mel_encoded])\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "    from keras.models import Model\n",
    "    from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Concatenate\n",
    "\n",
    "    # mfcc input\n",
    "    mfcc_input = Input(shape=(X_train['mfccs'].iloc[0].shape[0], X_train['mfccs'].iloc[0].shape[1], 1))\n",
    "\n",
    "    mfcc_x = Conv2D(32 , (3,3),activation = 'relu',padding='valid')(mfcc_input)  \n",
    "    mfcc_x = MaxPooling2D(2, padding='same')(mfcc_x)\n",
    "    mfcc_x = Conv2D(128, (3,3), activation='relu',padding='valid')(mfcc_x)\n",
    "    mfcc_x = MaxPooling2D(2, padding='same')(mfcc_x)\n",
    "    mfcc_x = Dropout(0.3)(mfcc_x)\n",
    "    mfcc_x = Conv2D(128, (3,3), activation='relu',padding='valid')(mfcc_x)\n",
    "    mfcc_x = MaxPooling2D(2, padding='same')(mfcc_x)\n",
    "    mfcc_x = Dropout(0.3)(mfcc_x)\n",
    "    mfcc_output = GlobalAveragePooling2D()(mfcc_x)\n",
    "\n",
    "    # melspectrogram input\n",
    "    mel_input = Input(shape=X_train_mel_encoded.shape[1:])\n",
    "    mel_x = Flatten()(mel_input)\n",
    "    mel_output = Dense(128, activation='relu')(mel_x)\n",
    "\n",
    "    combined = Concatenate()([mfcc_output, mel_output])\n",
    "    fc = Dense(512 , activation = 'relu')(combined)\n",
    "\n",
    "    output = Dense(50 , activation = 'softmax')(fc)\n",
    "\n",
    "    multi_input_model = Model(inputs=[mfcc_input, mel_input], outputs=output)\n",
    "\n",
    "    #multi_input_model.fit([X_train['mfccs'], X_train_mel_encoded], y_train, epochs=40, batch_size=8)\n",
    "    multi_input_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc'])\n",
    "    X_train_mfccs = np.array(X_train['mfccs'].tolist())\n",
    "    multi_input_model.fit([X_train_mfccs, X_train_mel_encoded], y_train, epochs=40, batch_size=8)\n",
    "\n",
    "    X_test_mel_encoded = encoder.predict(X_test_mel_scaled)\n",
    "    y_pred = multi_input_model.predict([X_test['mfccs'], X_test_mel_encoded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 66ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       1.00      0.50      0.67        12\n",
      "           2       0.78      0.88      0.82         8\n",
      "           3       0.86      0.67      0.75         9\n",
      "           4       0.50      0.40      0.44        10\n",
      "           5       0.73      1.00      0.84         8\n",
      "           6       0.67      0.80      0.73         5\n",
      "           7       0.19      0.75      0.30         4\n",
      "           8       0.78      0.78      0.78         9\n",
      "           9       0.71      0.83      0.77         6\n",
      "          10       0.50      1.00      0.67         5\n",
      "          11       0.88      0.64      0.74        11\n",
      "          12       0.88      0.64      0.74        11\n",
      "          13       0.60      0.43      0.50         7\n",
      "          14       0.62      0.80      0.70        10\n",
      "          15       0.57      0.50      0.53         8\n",
      "          16       0.46      0.67      0.55         9\n",
      "          17       0.89      1.00      0.94         8\n",
      "          18       0.83      0.71      0.77         7\n",
      "          19       0.86      0.75      0.80         8\n",
      "          20       1.00      0.75      0.86         8\n",
      "          21       0.50      0.50      0.50         4\n",
      "          22       1.00      0.88      0.93         8\n",
      "          23       0.86      0.60      0.71        10\n",
      "          24       0.67      0.75      0.71         8\n",
      "          25       0.20      0.33      0.25         3\n",
      "          26       0.75      0.43      0.55         7\n",
      "          27       1.00      0.75      0.86         8\n",
      "          28       1.00      0.46      0.63        13\n",
      "          29       1.00      0.40      0.57        10\n",
      "          30       0.71      0.62      0.67         8\n",
      "          31       0.67      0.73      0.70        11\n",
      "          32       1.00      0.62      0.77         8\n",
      "          33       0.57      0.57      0.57         7\n",
      "          34       0.70      0.70      0.70        10\n",
      "          35       0.26      0.50      0.34        10\n",
      "          36       0.86      0.67      0.75         9\n",
      "          37       0.67      0.80      0.73         5\n",
      "          38       0.60      0.60      0.60         5\n",
      "          39       0.75      0.86      0.80         7\n",
      "          40       0.38      0.38      0.38         8\n",
      "          41       0.44      0.36      0.40        11\n",
      "          42       0.44      0.89      0.59         9\n",
      "          43       0.86      0.50      0.63        12\n",
      "          44       0.64      0.64      0.64        11\n",
      "          45       0.33      0.60      0.43         5\n",
      "          46       0.88      0.78      0.82         9\n",
      "          47       0.40      0.40      0.40         5\n",
      "          48       0.67      1.00      0.80         4\n",
      "          49       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.65       400\n",
      "   macro avg       0.70      0.66      0.65       400\n",
      "weighted avg       0.72      0.65      0.66       400\n",
      "\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 40, 216, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 38, 214, 32)  320         ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_52 (MaxPooling2D  (None, 19, 107, 32)  0          ['conv2d_61[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 105, 128  36992       ['max_pooling2d_52[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_53 (MaxPooling2D  (None, 9, 53, 128)  0           ['conv2d_62[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 9, 53, 128)   0           ['max_pooling2d_53[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 51, 128)   147584      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_54 (MaxPooling2D  (None, 4, 26, 128)  0           ['conv2d_63[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 32, 54, 32)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 4, 26, 128)   0           ['max_pooling2d_54[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 55296)        0           ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 128)         0           ['dropout_17[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 128)          7078016     ['flatten_12[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256)          0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 512)          131584      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 50)           25650       ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,420,146\n",
      "Trainable params: 7,420,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test_labels, y_pred_labels))\n\u001b[0;32m     10\u001b[0m multi_input_model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m---> 11\u001b[0m plot_model(multi_input_model, to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel_plot.png\u001b[39m\u001b[39m'\u001b[39m, show_shapes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, show_layer_names\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test_mfccs = np.array(X_test['mfccs'].tolist())\n",
    "y_pred = multi_input_model.predict([X_test_mfccs, X_test_mel_encoded])\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 40, 216, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 38, 214, 32)  320         ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_52 (MaxPooling2D  (None, 19, 107, 32)  0          ['conv2d_61[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 105, 128  36992       ['max_pooling2d_52[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_53 (MaxPooling2D  (None, 9, 53, 128)  0           ['conv2d_62[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 9, 53, 128)   0           ['max_pooling2d_53[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 51, 128)   147584      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_54 (MaxPooling2D  (None, 4, 26, 128)  0           ['conv2d_63[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 32, 54, 32)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 4, 26, 128)   0           ['max_pooling2d_54[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 55296)        0           ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 128)         0           ['dropout_17[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 128)          7078016     ['flatten_12[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256)          0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 512)          131584      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 50)           25650       ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,420,146\n",
      "Trainable params: 7,420,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "multi_input_model.summary()\n",
    "multi_input_model.save('multi_input_model.h5')\n",
    "plot_model(multi_input_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
